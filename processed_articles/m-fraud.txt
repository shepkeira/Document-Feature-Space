aidriven methods for detecting and preventing online fraud
today is fraudsters leverage increasingly sophisticated techniques to infiltrate networks and cause harm
from distributed dns attacks to fake accounts account takeovers credential stuffing and card cracking their methods are varied and hard to detect let alone preventing online fraud
fraud can have a tremendous financial impact on an organization in any industry
bot attacks can function at extremely high speeds undetected and because they behave in a similar manner to humans they are difficult to spot
financial organizations may be an obvious target but businesses in retail and travel are equally vulnerable
for example a rising form of fraud in the travel industry involves purchasing requests
browserbased bots can flood a travel site with reservation requests and lock up prices and inventory which results in real buyers turning to competitors to reserve rooms and flights
and bots come in different forms one bot can hit a site multiple times or many bots can perform single actions simultaneously
even worse bots can be programmed to perform sequences of events just like a real user would which makes them very difficult to detect
being able to distinguish between botdriven and human behaviors is critical to an organization is strategy for preventing online fraud
aidriven techniques and solutions can help organizations do this and are particularly effective for this use case
by using the volume of data and traffic patterns and the way the requests come in they can spot patterns and determine whether actions are being performed by a bot or a human
better yet the machine learning algorithms behind the ai get smarter over time
related article
how data science is transforming financial systems
let is look at three aidriven approaches that can be used separately or better yet together to identify malicious bots
1 supervised machine learning traditional machine learning is supervised
in supervised machine learning a model is trained on a labeled dataset
this means a domainexpert human developer must label sample data and select what kind of input and output sample data will feed the algorithm
machine learning algorithms are used to make predictions about unavailable future or unseen data based on the labeled sample data
the two most common types of supervised machine learning are classification where incoming data is labeled and categorized based on past data samples and regression where the algorithm identifies patterns and calculates predictions of continuous outcomes
decision trees linear and logistic regression and support vectors are examples of supervised machine learning algorithms
because each of the fields in a dataset is different for example some contain a single number while others a textbased description each field must be turned into a feature
this takes manual work and requires developers with the domain expertise to understand the properties of each field and engineer the features
additionally supervised machine learning requires a large set of labeled data and someone must identify different kinds of threats as malicious or benign in advance
in many cases not enough sample data exists rendering the algorithm ineffective for detecting today is sophisticated and rapidly changing attacks
supervised machine learning is good for learning patterns but if the pattern changes they may not recognize a threat
engineers have to continually monitor whether things have changed continue to label data and train it then test and retrain the models
it is a big loop that is always turning
2 unsupervised machine learning in unsupervised machine learning the algorithms are not dependent on a human domain expert labeling the data
the algorithms are trained to look for anomalies in the data and trigger alerts to notify fraud operations teams to investigate potential threats
once the anomaly is flagged teams can label the data and use it to feed supervised machine learning algorithms
this accelerates the process of training models and improves their effectiveness
unsupervised machine learning is often used to segment data into clusters that can be further analyzed to identify patterns
two wellknown applications of unsupervised machine learning include segmenting markets for targeting customers and anomalyfraud detection
3 using natural language processing nlp to learn features from request headers natural language processing npl is the study of programming computers to process and analyze large amounts of natural textual data and nlp models can be used to automatically learn features from request headers requiring a reduced amount of input from security domain experts
using recent mldriven advances in nlp you can avoid turning fields into features and instead treat the headers as sentences or paragraphs then bundle all them together into a single feature vector
this requires far less collaboration with domain experts and increases performance as the model takes all features into consideration simultaneously
traditional machine learning limits the algorithm is performance any time you develop a feature you have to decide what information to keep and what information to do without
inputting a field into a model that includes a range such as the passing of time requires normalizing the data it contains
this reduces accuracy because you can not include infinite ranges
by training a model to treat headers as natural language you don not have to omit information
advances in nlp are being driven by open ai and other credible organizations such as gpt2